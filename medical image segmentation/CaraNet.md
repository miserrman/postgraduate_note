# CaraNet

## abstract

很少有CNN的研究考虑到小目标的分割，这篇论文提出了一种上下文轴向转换注意力网络



## Purpose

大多数CNN，专注于提升整体的分割性能，而不是专注于小目标物体的分割性能而不是专注于小目标物体举例来说，对于脑部肿瘤，肿瘤的大小代表了病人的存活率，所以对于小目标物体的分割非常重要，为了解决这个问题，我们提出了上下文门控注意力网络

贡献可以总结为以下几点：

* 提出了一种新型神经网络，可以解决小目标物体的分割问题
* 引入了一种评价小目标物体分割方法的损失函数
* 说明了CaraNet在小目标物体分割的优秀

## Method

![](D:\document\postgraduate\note\pic\cara1.PNG)

### A. 平行局部解码器

低层的特征图计算花费较大，但是对结果的贡献较小，所以我们使用了一个平行局部解码器，去聚合高层次特征，我们使用ResNet作为我们的backbone,我们使用PD来聚合encoder出来的结果

### B、上下文模块

为了得到图的上下文特征，我们使用通道只能特征金字塔模块，去获取不同尺度图片的信息，经过上下文模块，我们可以获取到多尺度高层信息
$$
f_{1}^{'},f_{2}^{'},f_{3}^{'},
$$

### C、扭转轴向注意力机制

注意力机制包括两部分：

轴向注意力路径和翻转轴向注意力路径

包括两条路径可以描述成：
$$
R_i = 1 - Sigmoid(S_i)
ARA = AA_i * R_i
$$

### 损失函数为

$$
L_{total} = L(G, S_g^{up}) + \sum^5_{i = 3}L(G,S_i^{up})
$$

对于一个分割模型，我们一开始计算测试集的平均dice系数，相似于计算直方图，我们将所有值分配到一系列的间隔中（不连续，不重叠，等长的），然后在这些值中计算dice系数