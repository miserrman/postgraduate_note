# 直肠息肉分割论文调查

## TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation

网络结合了Transformer和CNN的长处，使用了两个分支，中间使用fusion进行连接

![](D:\document\postgraduate\note\pic\transfusion1.PNG)

Bifusion model采用三个分支

t的分支采用通道注意力机制

g的分支采用空间注意力机制

![](D:\document\postgraduate\note\pic\transfuse2.PNG)

### 注意力机制的分类

* 注意力机制
* 自注意力机制
* 软注意力机制：软注意力是一个[0,1]间的连续分布问题，更加关注区域或者通道，软注意力是确定性注意力，学习完成后可以通过网络生成，并且是可微的，可以通过神经网络计算出梯度并且可以前向传播和后向反馈来学习得到注意力的权重。包括空间注意力机制，通道注意力机制

### 通道注意力机制

![](https://xiaoyufenfei.github.io/2019/09/11/tong-dao-zhu-yi-li-ji-zhi-senet/Figure-2.png)

首先考察输出特征每个通道的信号，压缩（squeeze）全局空间信息为通道描述符，使用全局平均池化来生成各通道的统计量。

第二就是考察各通道的依赖程度，实现函数有两个标准：一是要灵活，二是要学习一个非互斥的关系，因为可能多个通道都会对结果有影响。本文使用带sigmoid激活函数的门限机制来实现。为了限制模型复杂度并增强泛化能力，门限机制中使用bottleneck形式的两个全连接层，第一个FC层降维至1/r，r为超参数，本文取16，具体见6.3实验。最后的sigmoid函数就是各通道的权重，根据输入数据调节各通道特征的权重，有助于增强特征的可分辨性。
![](D:\document\postgraduate\note\pic\transfuse2.PNG)

### 空间注意力机制

## Spatial Transformer Networks

空间注意力机制可以被总结为三个部分

![](D:\document\postgraduate\note\pic\space_transformer.PNG)

* 首先一个本地化网络(3.1节)获取输入的feature map，并通过多个隐藏层输出应该应用到feature map的空间变换参数
* 这给出了一个基于输入的变换。然后，使用预测的变换参数来创建一个采样网格，该网格是输入映射应该被采样以产生变换后的输出的一组点。
* 最后，以特征图和采样网格为输入

如果网络能够对经过平移、旋转、缩放及裁剪等操作的图片得到与未经变换前相同的检测结果，我们就说这个网络具有空间变换不变性（将平移、旋转、缩放及裁剪不变性统称为空间不变性）。具有空间变换不变性的网络能够得到更精确地分类结果。传统CNN网络的池化层具有平移不变性（网络在平移小于池化矩阵的范围时具有平移不变性。所以只有平移小于这个范围，才能保证平移不变性。），但是CNN网络对于大尺度的空间变换并不具备不变性。Spatial Transformer Networks提出的空间网络变换层，具有平移不变性、旋转不变性及缩放不变性等强大的性能。这个网络可以加在现有的卷积网络中，提高分类的准确性。

如下图所示：输入手写字体，我们感兴趣的是黄色框中的包含数字的区域，那么在训练的过程中，学习到的空间变换网络会自动提取黄色框中的局部数据特征，并对框内的数据进行空间变换，得到输出output。综上所述，空间变换网络主要有如下三个作用：

- 可以将输入转换为下一层期望的形式
- 可以在训练的过程中自动选择感兴趣的区域特征
- 可以实现对各种形变的数据进行空间变换

### 1. 本地化网络

### 2. 网格变换

. Parameterised Sampling Grid-参数化网格采样

此步骤的目地是为了得到输出特征图的坐标点对应的输入特征图的坐标点的位置。计算方式如下：

![img](https://pic1.zhimg.com/80/v2-86c8f1ebc151b38375e731c0e4bd09bc_hd.jpg)

![img](https://pic2.zhimg.com/80/v2-b2e15a8a0bf7bd2a124bdacfe9819135_hd.jpg)

式中s代表输入特征图像坐标点，t代表输出特征图坐标点， ![A_{\theta}](https://www.zhihu.com/equation?tex=A_%7B%5Ctheta%7D) 是局部网络的输出。这里需要注意的是坐标的映射关系是从目标图片——>输入图片。这是因为输入图片与目标图片坐标点均是人为定义的标准化格点矩阵，x，y的值在-1到1之间，图片任何一个位置的坐标点是固定不变的。这就好比两个坐标完全一样的图像，无论用谁乘以仿射变换矩阵，都可以得到经过仿射变换后的图像与原坐标点的映射关系。也就是说这里即使把坐标的映射关系变为输入图片——>目标图片得到的也是一样的映射关系。至于为什么要使用前者来求解这种映射关系，个人理解的是目标图片是我们期望的输出，我们通常以输出为参考，依次获得目标图片在每个坐标点的像素值。比如目标图片坐标点（0,0）对应输入图片坐标点（3,1），我们就先取出输入图片坐标点（3,1）处的像素值，这样依次获得目标图片在每个坐标点的像素值。通过上面的解释相信你们也能理解为什么没有使用仿射变换的逆矩阵。

通过这一步，我们已经得到变换后的输出特征图每个位置的坐标在输入特征图上的对应坐标点。下面我们就可以直接提取出输入特征图的每个位置的像素值（tensorflow有专门的函数可以得到指定位置的像素值）。在提取像素值之前，我们应该注意到一点：目标图片的坐标点对应的输入图片的坐标点不一定是整数坐标点（例如目标图片坐标点（0,1）对应输入图片坐标点（3.2,1.3）），而仅仅整数坐标才能提取像素值，所以需要利用插值的方式来计算出对应该点的灰度值（像素值）。可以看出，步骤一为步骤二提供了仿射变换的矩阵，步骤二为步骤三提供了输出特征图的坐标点对应的输入特征图的坐标点的位置，步骤三只需要提取这个对应的坐标点的像素值(非整数坐标需要使用双向性插值提取像素值)就能最终得到输出特征图V。

### 不变性

不变性意味着即使目标的外观发生了某种变化，但是你依然可以把它识别出来。这对图像分类来说是一种很好的特性，因为我们希望图像中目标无论是被平移，被旋转，还是被缩放，甚至是不同的光照条件、视角，都可以被成功地识别出来。

所以上面的描述就对应着各种不变性：

- 平移不变性：Translation Invariance

- 旋转/视角不变性：Ratation/Viewpoint Invariance

- 尺度不变性：Size Invariance

- 光照不变性：Illumination Invariance

- 在欧几里得几何中，平移是一种几何变换，表示把一幅图像或一个空间中的每一个点在相同方向移动相同距离。比如对图像分类任务来说，图像中的目标不管被移动到图片的哪个位置，得到的结果（标签）应该是相同的，这就是卷积神经网络中的平移不变性。

  **平移不变性意味着系统产生完全相同的响应（输出），不管它的输入是如何平移的 。平移同变性（translation equivariance）意味着系统在不同位置的工作原理相同，但它的响应随着目标位置的变化而变化** 。比如，实例分割任务，就需要平移同变性，目标如果被平移了，那么输出的实例掩码也应该相应地变化。最近看的FCIS这篇文章中提到，一个像素在某一个实例中可能是前景，但是在相邻的一个实例中可能就是背景了，也就是说，同一个像素在不同的相对位置，具有不同的语义，对应着不同的响应，这说的也是平移同变性。

  **为什么卷积神经网络具有平移不变性**

  简单地说，卷积+最大池化约等于平移不变性。

  - 卷积：简单地说，图像经过平移，相应的特征图上的表达也是平移的。下图只是一个为了说明这个问题的例子。输入图像的左下角有一个人脸，经过卷积，人脸的特征（眼睛，鼻子）也位于特征图的左下角。假如人脸特征在图像的左上角，那么卷积后对应的特征也在特征图的左上角。 （如下两幅图所示）

  ​    在神经网络中，卷积被定义为不同位置的特征检测器，也就意味着，无论目标出现在图像中的哪个位置，它都会检测到同样的这些特征，输出同样的响应。比如人脸被移动到了图像左下角，卷积核直到移动到左下角的位置才会检测到它的特征。

  ![](https://img-blog.csdnimg.cn/20200729155437698.png)

  

  - 池化：比如最大池化，它返回感受野中的最大值，如果最大值被移动了，但是仍然在这个感受野中，那么池化层也仍然会输出相同的最大值。这就有点平移不变的意思了。

    所以这两种操作共同提供了一些平移不变性，即使图像被平移，卷积保证仍然能检测到它的特征，池化则尽可能地保持一致的表达。

**仿射变换（Affine transformation）**

其实上面几种常见变换都可以用同一种变换来表示，就是仿射变换，它有更一般的形式，如下：

![img](https://pic2.zhimg.com/80/v2-a213b987fe4c1a4e4d55229ef6cd4c45_hd.jpg)

a,b,c,d,e,f取不同的值就可以表示上述不同的变换。当6个参数取其上述变换以外的值时，为一般的仿射变换，效果相当于从不同的位置看同一个目标。

**2.双线性插值（Bilinear Interpolation）**

在对图像进行仿射变换时，会出现一个问题，当原图像中某一点的坐标映射到变换后图像时，坐标可能会出现小数，而我们知道，图像上某一像素点的位置坐标只能是整数，那该怎么办？这时候双线性插值就起作用了。在介绍双线性插值之前，先讲一下线性插值的计算方法：已知点 (x0, y0) 与 (x1, y1)，要计算 [x0, x1] 区间内某一位置 x 在直线上的y值，可以采用两点式写出直线方程并求得y的取值如下：

![img](https://pic3.zhimg.com/80/v2-03201d13801505e09f96130d5def77da_hd.jpg)

